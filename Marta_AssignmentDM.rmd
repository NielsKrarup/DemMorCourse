---
title: "Demography and Mortality"
author: "xxx, yyy, zzz, Niels Moctezuma Krarup"
date: "3 october 2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE)
#knitr::opts_knit$set(root.dir = "/Users/nielskrarup/Desktop/UNI/courses/DemMorCourse/" )

library("survival")
library("timereg")
library("SASxport")
library("dplyr")
library("purrr")
library("lattice")
library("hexbin")
library("ggplot2")
library(gridExtra)
library(pander)

```


\section{Part 1}
#Part1
Let the setup and notation be as stated in the assignment.

\subsection{1.1)}
## 1.1
From the definition of the expected residual life, $e_i(0) = \int_0^\infty S_i(u|0)du = \int_0^\infty \frac{S_i(u)}{S_i(0)}du = \int_0^\infty S_i(u)du$, since $S_i(0) = 1$. For ease of notation write $M_i = M_i(u) = \int_0^u\mu_i(z)dz, \quad i = 1,2$ we have

\begin{align*}
e_2(0) - e_1(0)  &= \int_0^\infty e^{-M_2}du - \int_0^\infty e^{-M_1}du \\
                 &= \int_0^\infty e^{-M_2} - e^{-M_1}du  \\
                 &= \int_0^\infty \left[  e^{M_1-M_2} - 1\right] e^{-M_1}du 
\end{align*}
Now, since $e^{-M_1} = S_1(u)$ and noting that 
$$ \frac{d}{du} -S_1(u)e_i(u) = 
\frac{d}{du} -S_1(u)\int_u^\infty \frac{S_1(z)}{S_1(u)}du =
\frac{d}{du} -\int_u^\infty S_1(z)dz = S_1(u),$$

by the fundamental theorem of calculus and switching limits of the integral. Then using integration by parts we get
\begin{align*}
\int_0^\infty \left[  e^{M_1-M_2} - 1\right] e^{-M_1}du   &= 
\left[ (e^{M_1-M_2}-1)(-S_1(u)e_1(u)) \right]_0^\infty - \int_0^\infty (M_1 - M_2)^\prime e^{M_1 - M_2}(-S_1(u)e_1(u))du     \\
&= \int_0^\infty (\mu_1(u) - \mu_2(u)) e^{\int_0^u \mu_1(v) - \mu_2(v)dv}S_1(u)e_1(u)du
\end{align*}

##Problem 1.2 
For this subproblem we will mainly be using Appendix 3.1 on page 69, in wich we find several expressions for the terms used in Arriagas decomposition. 

First we will look at the Direct effect term. 
We start off by inserting expressions from p.69 for $n L_{x}$ in the decomposition. And we get: 

$$ \frac{l_{x}^{1}}{l_{0}^{1}} \left( \frac{l_{x}^{2} \int_{x}^{y} e^{- \int_{x}^{a} \mu_{2} (u) du} da}{l_{x}^{2}} - 
\frac{l_{x}^{1} \int_{x}^{y} e^{- \int_{x}^{a} \mu_{1} (u) du} da}{l_{x}^{1}} \right) $$ 

We see that $l_{x}^{2}$ and $l_{x}^{1}$ terms cancel out in the fractions. As they cancel out and as we use a expression from p.69 for $l_{x}^{1}$ in insert in the fraction outside of the pharentesis, we get: 

$$ \frac{l_{0}^{1} e^{ - \int_{0}^{x} \mu_{1} (u)du }}{l_{0}^{1}} \left( \int_{x}^{y} e^{- \int_{x}^{a} \mu_{2} (u) du} - e^{- \int_{x}^{a} \mu_{1} (u) du} da \right) $$

And as $ l_{0}^{1}$ cancel out in the fraction, we see that the exponential term in the nominator is actually a survival function and my using some basic rules of integrations we then get the following equations: 

$$ S_{1} (x) \cdot \left(  \int_{x}^{y} \left( \frac{e^{- \int_{0}^{x} \mu_{2} (u) du - \int_{x}^{a} \mu_{2} (u) du} } {e^{- \int_{0}^{x} \mu_{2} (u) du}} - 
\frac{e^{- \int_{0}^{x} \mu_{1} (u) du - \int_{x}^{a} \mu_{1} (u) du} } {e^{- \int_{0}^{x} \mu_{2} (u) du}} \right)da  \right) $$. 
$$ = 
S_{1} (x) \cdot \left( \int_{x}^{y} \frac{e^{- \int_{0}^{a} \mu_{2} (u) du}}{e^{- \int_{0}^{x} \mu_{2} (u) du}} - \frac{e^{- \int_{0}^{a} \mu_{1} (u) du}}{e^{- \int_{0}^{x} \mu_{1} (u) du}} da \right) $$ . $$ S_{1} (x) \left( \int_{x}^{y} \frac{S_{2}(a)}{S_{2}(x)} - 
\frac{S_{1}(a)}{S_{1}(x)} \right) da = S_{1} (x)
\left( \int_{x}^{y} S_{2} (a|x) - 
S_{1} (a|x) da \right) = S_{1} (x) \cdot \left( e_{2}(x,y) - e_{1}(x,y) \right) $$ 
\\
We have now expressed the direct effect in terms of our usual notation. 

Next we will be looking at the expression for the indirect effect 

First we will once again use the expressions from page 69. We see that $\frac{l_{x}}{l_{y}} = nP_{x} $ and after rearranging our fractions and then inserting that we get the following: 

$$ \frac{T_{y}^{1}}{l_{0}^{1}} \cdot \left( e^{\int_{x}^{y} \mu_{1} (u) du} \cdot e^{- \int_{x}^{y} \mu_{2} (u) du} - 1 \right) $$ 

Then by applying some integral rules we obtain the following: 

$$ \frac{T_{y}^{1}}{l_{0}^{1}} \cdot \left( 
\frac{e^{\int_{x}^{y} \mu_{1} (u) du} \cdot e^{- \int_{x}^{y} \mu_{1} (u) du}}{e^{-\int_{x}^{y} \mu_{1} (u) du}} \cdot \frac{e^{- \int_{x}^{y} \mu_{2} (u) du} \cdot e^{\int_{0}^{x} \mu_{2} (u) du}}{e^{\int_{0}^{x} \mu_{2} (u) du}} -1 \right) $$. 

= $$ \frac{T_{y}^{1}}{l_{0}^{1}} \cdot \left( 
\frac{1}{e^{-\int_{x}^{y} \mu_{1} (u) du}} \cdot 
\frac{e^{- \int_{0}^{y} \mu_{2} (u) du}} {e^{\int_{0}^{x} \mu_{2} (u) du}} -1 \right) = \frac{T_{y}^{1}}{l_{0}^{1}} \cdot \left( 
\frac{e^{- \int_{0}^{x} \mu_{1} (u) du}} {e^{-\int_{0}^{y} \mu_{1} (u) du}} \cdot S_{2} (y|x) -1 \right) $$ . 

$$ = \frac{T_{y}^{1}}{l_{0}^{1}} \cdot \left( 
\frac{S_{1}(x)}{S_{1}(y)} \cdot S_{2} (y|x) -1 \right) $$ 

We only need to think about the fraction outside of the pharentesis now . We have that $T_{y}^{1} = e_{y}^{1} \cdot l_{y}^{1}$ and that $l_{y}^{1} = l^{1} (0) \cdot e^{- \int_{0}^{y} \mu_{1} (u) du}$ So by that we get: 

$$ \frac{e_{y} l^{1} (0) \cdot e^{- \int_{0}^{y} \mu_{1} (u) du} }{l_{0}^{1}} \cdot \left( \frac{S_{1}(x)}{S_{1}(y)} \cdot S_{2} (y|x) -1 \right) = e_{y} \cdot S_{1} (y) \left( \frac{S_{1}(x)}{S_{1}(y)} \cdot S_{2} (y|x) -1 \right) = = e_{y}^{1} \cdot S_{1} (x) \cdot S_{2} (y|x) - e_{y}^{1} \cdot S_{1} (y) $$. 


We finally just need to write the last part of the decomposition. The interaction effect. We have looked at $T_{y}$ and for $l_{y}$ before and we will use the same again and get following: 

$$ X(x,y)= \left( \frac{e_{y}^{2} \cdot l_{y}^{2} - e_{y}^{1} \cdot l_{y}^{1} \frac{l_{y}^{2}}{l_{y}^{1}}}{l_{0}^{1}} \right) \cdot \left( \frac{l_{x}^{1}}{l_{x}^{2}} - \frac{l_{y}^{1}}{l_{y}^{2}} \right) = l^{2} (0) e^{- \int_{0}^{y} \mu_{2} (u) du} \cdot \left(   \frac{e_{y}^{2} - e_{y}^{1}}{l_{0}^{1}} \right)  \cdot  \left( \frac{l_{x}^{1}}{l_{x}^{2}} - \frac{l_{y}^{1}}{l_{y}^{2}} \right) 
$$. 

$$  \frac{l_{0}^{2}}{l_{0}^{1}} \cdot S_{2} (y) \cdot \left(  e_{y}^{2} - e_{y}^{1} \right) \cdot \left( \frac{l_{x}^{1}}{l_{x}^{2}} - \frac{l_{y}^{1}}{l_{y}^{2}} \right) = S_{2} (y) \cdot \left(  e_{y}^{2} - e_{y}^{1} \right) \cdot \left( \frac{l_{0}^{2}}{l_{0}^{1}} \cdot \frac{l_{x}^{1}}{l_{x}^{2}} - \frac{l_{0}^{2}}{l_{0}^{1}} \cdot \frac{l_{y}^{1}}{l_{y}^{2}} \right) $$ . 

$$ S_{2} (y) \cdot \left(  e_{y}^{2} - e_{y}^{1} \right) \left( \frac{l_{0}^{2}}{l_{0}^{1}} \cdot \frac{l^{1} (0) e^{- \int_{0}^{x} \mu_{1} (u) du}}{l^{2} (0) e^{- \int_{0}^{x} \mu_{2} (u) du}} - \frac{l_{0}^{2}}{l_{0}^{1}} \cdot \frac{l^{1} (0) e^{- \int_{0}^{y} \mu_{1} (u) du}}{l^{2} (0) e^{- \int_{0}^{y} \mu_{2} (u) du}} \right) $$ . 

$$ S_{2} (y) \cdot \left(  e_{y}^{2} - e_{y}^{1} \right) \left( \frac{e^{- \int_{0}^{x} \mu_{1} (u) du}}{e^{- \int_{0}^{x} \mu_{2} (u) du}} - \frac{e^{- \int_{0}^{y} \mu_{1} (u) du}}{e^{- \int_{0}^{y} \mu_{2} (u) du}} \right) = S_{2} (y) \cdot \left(  e_{y}^{2} - e_{y}^{1} \right) \left(  \frac{S_{1} (x)}{S_{2} (x)} -  \frac{S_{1} (y)}{S_{2} (y)} \right)$$ 

## Problem 1.3

We want to show that for any $x$ and $y$ with $x<y$
$$D(x,y)+I(x,y)=A(x,y)$$
We have from question 1.2 that 
\begin{align*} 
D(x,y) &= S_1(x)(e_2(x,y)-e_1(x,y)) \\
I(x,y) &= e_1(y)S_1(x)S_2(y \mid x) - e_1(y)S_1(y) 
\end{align*}


Having a look at $D(x,y)$ we get by rewriting:
\begin{align*}
D(x,y) & = S_1(x)(e_2(x,y)-e_1(x,y)) \\
& =  S_1(x)\left( \int_x^y S_2(z \mid x)dz - \int_x^y S_1(z \mid x) dz \right) \\
& = S_1(x)\left( \int_x^y \frac{S_2(z)}{S_2(x)}dz - \int_x^y \frac{S_1(z)}{S_1(x)} dz \right)
\end{align*}
Inserting the expressions for $S_1(x)$ and $S_2(x)$ we get:

\begin{align*}
& = S_1(x)\left( \int_x^y \frac{e^{-\int_0^z \mu_2(u)du}}{e^{-\int_0^x \mu_2(u)du}}dz - \int_x^y \frac{e^{-\int_0^z \mu_1(u)du}}{e^{-\int_0^x \mu_1(u)du}} dz \right) \\
& = S_1(x)\left( \int_x^y e^{-\int_0^z \mu_2(u)du +\int_0^x \mu_2(u)du}dz - \int_x^y e^{-\int_0^z \mu_1(u)du +\int_0^x \mu_1(u)du} dz \right) \\
\end{align*}

Using that $-\int_0^z f(z)dz + \int_0^x f(z)dz = - \int_0^z f(z)dz- \int_x^0 f(z)dz = -\int_x^z f(z)dz$ and collecting the integral over z we get

\begin{align*} 
& = S_1(x)\left( \int_x^y e^{-\int_x^z \mu_2(u)du} - e^{-\int_x^z \mu_1(u)du} dz \right) \\
\end{align*}

Writing out $S_1(x)$ and rearranging the terms we get: 
\begin{align*}
& = S_1(x)\left( \int_x^y \left(e^{-\int_x^z (\mu_2(u)-\mu_1(u))du} - 1 \right) e^{-\int_x^z \mu_1(u)du} dz \right) \\
& = e^{-\int_0^x \mu_1(u)du}\left( \int_x^y \left(e^{\int_x^z (\mu_1(u)-\mu_2(u))du} - 1 \right) e^{-\int_x^z \mu_1(u)du} dz \right) \\
& = \left( \int_x^y \left(e^{\int_x^z (\mu_1(u)-\mu_2(u))du} - 1 \right) e^{-\int_0^z \mu_1(u)du} dz \right) \\
\end{align*}

Using partial integration with $u(z)=e^{\int_x^z (\mu_1(u)-\mu_2(u))du} - 1$ and $v'(z)=e^{-\int_0^z \mu_1(u)du}$ we recognize $\int v'(z)dz =-S_1(z)e_1(z)$ since

\begin{align*}
v'(z) & = S_1(z) \\
      & = \frac{d}{dz} - \int_z^{\infty} S_1(u) du \\
      & = \frac{d}{dz} - S_1(z) \int_z^{\infty} \frac{S_1(u)}{S_1(z)} du \\
      & = \frac{d}{dz} -S_1(z)e_1(z) 
\end{align*}

and 

\begin{align*}
\frac{d}{dz} u(z) & = \frac{d}{dz} e^{\int_x^z (\mu_1(u)-\mu_2(u))du} -1 \\
    & = (\mu_1(z)-\mu_2(z)) e^{\int_x^z (\mu_1(u)-\mu_2(u))du}
\end{align*}

Collecting we thus get

\begin{align*}
\int_x^y u(z)v'(z) dz & = \left[u(z)v(z)\right]_x^z - \int_x^y u'(z)v(z) dz \\
& =\left[\left(e^{\int_x^z (\mu_1(u)-\mu_2(u))du}-1\right)\left(-S_1(z)e_1(z)\right)\right]_x^y \\
& \hspace{0.2 cm} - \int_x^y (\mu_1(z)-\mu_2(z)) e^{\int_x^z (\mu_1(u)-\mu_2(u))du}(-S_1(z)e_1(z)) \\
& =\left[\left(e^{\int_x^z (\mu_1(u)-\mu_2(u))du}-1\right)\left(-S_1(z)e_1(z)\right)\right]_x^y \\
& \hspace{0.2 cm} + \int_x^y (\mu_1(z)-\mu_2(z)) e^{\int_x^z (\mu_1(u)-\mu_2(u))du}S_1(z)e_1(z)
\end{align*}

We recognize the second term as $A(x,y)= \int_x^y (\mu_1(z)-\mu_2(z)) e^{\int_x^z (\mu_1(u)-\mu_2(u))du}S_1(z)e_1(z)$. So in order to show that $D(x,y)+I(x,y)=A(x,y)$ holds, we now need to show that $A(x,y)-D(x,y)=I(x,y)$ i.e. we need to show that

\begin{align*}
-\left[\left(e^{\int_x^z (\mu_1(u)-\mu_2(u))du}-1\right)\left(-S_1(z)e_1(z)\right)\right]_x^y = I(x,y)
\end{align*}

Rewriting the left hand side we get

\begin{align*}
& -\left[\left(e^{\int_x^z (\mu_1(u)-\mu_2(u))du}-1\right)\left(-S_1(z)e_1(z)\right)\right]_x^y \\
 = & - \left(e^{\int_x^y \mu_1(u)-\mu_2(u) du} -1\right)(-S_1(y)e_1(y)) + 0 \\
= &  \left(e^{\int_x^y \mu_1(u)-\mu_2(u) du} -1\right)(S_1(y)e_1(y)) \\
 = & e^{\int_x^y \mu_1(u)-\mu_2(u) du}e^{-\int_0^y \mu_1(u)du}e_1(y) + S_1(y)e_1(y) \\
 = & e^{-\int_x^y \mu_2(u) du + \int_x^y \mu_1(u)du -\int_0^y \mu_1(u)du}e_1(y) + S_1(y)e_1(y) \\
\end{align*}

Using that $-\int_x^y f(z)dz = - \int_0^y f(z)dz - \int_x^0 f(z)dz = - \int_0^y f(z)dz + \int_0^x f(z)dz$ and that $\int_x^y f(z)dz - \int_0^y f(z)dz = \int_x^y f(z)dz + \int_y^0 f(z)dz = \int_x^0 f(z)dz = - \int_0^x f(z)dz$ we get:

\begin{align*}
= & e^{-\int_0^y \mu_2(u) du + \int_0^x \mu_2(u)du} e^{ - \int_0^x \mu_1(u)du}e_1(y) + S_1(y)e_1(y) \\
= & \frac{ e^{-\int_0^y \mu_2(u) du}}{e^{ - \int_0^x \mu_2(u)du}} S_1(x)e_1(y) + S_1(y)e_1(y) \\
= & \frac{ S_2(y)}{S_2(x)} S_1(x)e_1(y) + S_1(y)e_1(y) \\
= & S_2(y \mid x) S_1(x)e_1(y) + S_1(y)e_1(y) \\
= & I(x,y)
\end{align*}
as wanted.

\section*{1.7)}
## 1.7
```{r,results='hide'}
source("Code/structure.R")
```

Question 1.7: Compute and visualize the period life expectancy at birth for both sexes over the period 1835 − 2020.

We start by creating an HMD object, with Dansih data, and using the corresponding class function "getSmoothMu" to get the smoothed mortality surface.


```{r}

HMDobj <- HMDdatClass$new(
  Otxtfile = 'Data/DNK_Deaths_1x1.txt', 
  Etxtfile = 'Data/DNK_Exposures_1x1.txt'
  )

surf_obj <- HMDobj$getSmoothMu()
```


From the surf object, we can use the aux-function "surf2lifeexp" to calculate Period life expectancies for all groups, ages = 0, and all times. 
Then plot using the aux-function **life.exp.base** 

```{r, fig.width=12}
lifeexp_obj <- surf2lifeexp(surf = surf_obj, agelim = 0, type = "period")

plot_dat_lifeexp <- reshape2::melt(lifeexp_obj$lifeexp , varnames = c("Group", "Age", "Year"), value.name = "PeriodLifeExp")

ggplot(data = plot_dat_lifeexp, aes(x = Year, y = PeriodLifeExp, fill = Group)) + geom_bar(stat = "identity", position = position_dodge())

ggplot(data = plot_dat_lifeexp, aes(x = Year, y = PeriodLifeExp, col = Group)) + geom_line()
```

\section{1.8}
## 1.8

Question 1.8: Compute and visualize, using e.g. a bar plot, the average annual rate of mortality improvement for both sexes and the age groups and periods stated above.

Mortality improvement rates is defined in Vaupel & Romo (2003) eq. (4) as 
$$\rho(a,t) = -\acute{\mu}(a,t) = \frac{\frac{\partial}{\partial t}\mu(a,t)}{\mu(a,t)} = - \frac{d}{dt} log \mu(a,t)$$. 


While the average pace of mortality improvement is defined in eq. (6):
$$\bar{\rho}(t) = \int_0^\infty \rho(a,t) \mu(a,t) S(a,t) du = \int_0^\infty \rho(a,t) f(a,t) da$$

Where $f(a,t)$ is the distribution of deaths among the period $t$ cohort.  
Since we get data by 1x1 format, we are not able to get analytical expressions for the derivative wrt time or age for that matter.

Hence we will use the observed data for the distribution of deaths, and the estimates from the smoothed $\mu$-surface, then using the approximation 
$$
\rho(a,t) \approx \frac{\mu(a, t+1)-\mu(a,t)}{\mu(a,t)}
$$

```{r,}
#get deaths
deaths <- HMDobj$getOEdata()
HMDobj$initialize 



```

## Problem 2.1
The pros of estimating the model by a poisson distribution instead of using the OLS approach is that we don't have to worry about handling empty cells, for example if there are zero deaths in a given year. Especially in small populations it is a good idea to use the poisson distribution. The cons of using the poisson distribution is that we may miss some information hidden in the data.

## Problem 2.2

```{r}

HMDobj <- HMDdatClass$new(
  Otxtfile = 'Data/GBRCENW_Deaths_1x1.txt', 
  Etxtfile = 'Data/GBRCENW_Exposures_1x1.txt'
  )

surf_obj <- HMDobj$getSmoothMu()
```
Take both sexes for ages 20-100 in the years 1970-2018:
```{r}
OEdata <- HMDobj$getOEdata(agelim = c(20,100), timelim = c(1970, 2018))
```

We want to estimate the models parameters $\alpha_t$ and $\beta_t$ in the CBD model by using the Poisson assumption:

$$ D(x,t)\mid E(x,t) \sim Poisson(E(x,t)\mu(x,t))$$
We already know the exposures from our data, so we get the distribution by estimating $\mu(x,t)$ in terms of $\alpha$ and $beta$. We know that 

$$ q(x,t)=1-exp(-\mu(x,t))$$

and 

$$\log\left( \frac{q(x,t)}{1-q(x,t)} \right) = \alpha_t + \beta_t(x-\bar{x})$$
Inserting and isolating $\mu(x,t)$ we get:

$$ \log\left( \frac{1-exp(-\mu(x,t))}{1-(1-exp(-\mu(x,t)))} \right) = \alpha_t + \beta_t(x-\bar{x})$$
$$ \Leftrightarrow \frac{1-exp(-\mu(x,t))}{exp(-\mu(x,t)))} = exp(\alpha_t + \beta_t(x-\bar{x}))$$
$$ \Leftrightarrow \frac{\frac{1}{exp(-\mu(x,t))}-\frac{exp(-\mu(x,t))}{exp(-\mu(x,t))}}{\frac{exp(-\mu(x,t)))}{exp(-\mu(x,t))}} = exp(\alpha_t + \beta_t(x-\bar{x}))$$
$$ \Leftrightarrow \frac{\frac{1}{exp(-\mu(x,t))}-1}{1} = exp(\alpha_t + \beta_t(x-\bar{x}))$$
$$ \Leftrightarrow \frac{1}{exp(-\mu(x,t))}-1 = exp(\alpha_t + \beta_t(x-\bar{x}))$$
$$ \Leftrightarrow \frac{1}{exp(-\mu(x,t))} = exp(\alpha_t + \beta_t(x-\bar{x}))+1$$

$$ \Leftrightarrow exp(-\mu(x,t)) = \frac{1}{exp(\alpha_t + \beta_t(x-\bar{x}))+1}$$
$$ \Leftrightarrow -\mu(x,t) = \log \left(\frac{1}{exp(\alpha_t + \beta_t(x-\bar{x}))+1}\right)$$
$$ \Leftrightarrow \mu(x,t) = -\log \left(\frac{1}{exp(\alpha_t + \beta_t(x-\bar{x}))+1}\right)$$
Inserting this expression for $\mu(x,t)$ into the Poisson distribution, we want to estimate a Poisson distribution with the parameters: 

$$ D(x,t)\mid E(x,t) \sim Poisson \left(E(x,t)\left(-\log \left(\frac{1}{exp(\alpha_t + \beta_t(x-\bar{x}))+1}\right)\right) \right)$$ 

The estimators $\alpha_t$ and $\beta_t$ have 48 dimensions i.e. we get one parameter for each year.

We get that the log-likelihood function for the Poisson distribution is:

$$ l(\lambda)=\sum_{t=1970}^{2018}\sum_{x=20}^{100} D_{t,x}\log\lambda_{t,x} - \lambda_{t,x}-\log D_{t,x}!  $$
$$ \Leftrightarrow l((\alpha_{1970},\beta_{1970}),...,(\alpha_{2018},\beta_{2018}))$$
$$= \sum_{t=1970}^{2018}\sum_{x=20}^{100} D_{t,x}\log\left(E(x,t)\left(-\log \left(\frac{1}{exp(\alpha_t + \beta_t(x-\bar{x}))+1}\right)\right) \right) - \left(E(x,t)\left(-\log \left(\frac{1}{exp(\alpha_t + \beta_t(x-\bar{x}))+1}\right)\right) \right)\\-\log D_{t,x}!$$

$$= \sum_{t=1970}^{2018}\sum_{x=20}^{100} D_{t,x}\log\left(E(x,t) \log (exp(\alpha_t + \beta_t(x-\bar{x}))+1 ) \right) - \left(E(x,t)\log \left(exp(\alpha_t + \beta_t(x-\bar{x}))+1\right)\right)-\log D_{t,x}!$$

Writing the log-likelihood and using optim to maximize minus the log-likelihood(same as minimizing the loglikelihood) we get:

*MISSING CODE*
```{r}
# Setup
HMDobj <- HMDdatClass$new(Otxtfile = 'Data/GBRCENW_Deaths_1x1.txt', 
                          Etxtfile = 'Data/GBRCENW_Exposures_1x1.txt')

xmin <- 20
xmax <- 100
xvec <- xmin:xmax
xbar <- sum(x)/(xmax-xmin+1) #mean of the agespan considered = 60

tmin <- 1970
tmax <- 2018

# Log-likelihood funktion
loglike <- function(par,Dvec,Evec,xvec) {
    mu <- log(exp(par[1]+par[2]*(xvec-mean(xvec)))+1)
    -sum(Dvec*log(mu)-Evec*mu)
}

Betahat <- matrix(NA, nrow = (tmax-tmin+1),ncol = 1)
Alphahat <- matrix(NA, nrow = (tmax-tmin+1),ncol = 1)
# Optimize minus log-likelihooden for females
for(i in 1:(tmax-tmin+1)){
  Dtest  <- OEdata$O["Female",,i] #    Dødsfald for kvinder i år i aldre xmin til xmax
  Etest  <- OEdata$E["Female",,i] # Eksponering for kvinder i år i aldre xmin til xmax
  opt <- optim(c(-4,0.1), function(par) loglike(par,Dtest,Etest,xvec))
  Betahat[i] <- opt$par[2] # beta parametre under Poisson antagelsen for kvinder i år i
  Alphahat[i] <- opt$par[1]# alpha  parametre under Poisson antagelsen for kvinder i år i
}

Betahat_f <- Betahat
Alphahat_f <- Alphahat 

Betahat <- matrix(NA, nrow = (tmax-tmin+1),ncol = 1)
Alphahat <- matrix(NA, nrow = (tmax-tmin+1),ncol = 1)
# Optimer minus log-likelihooden
for(i in 1:(tmax-tmin+1)){
  Dtest  <- OEdata$O["Male",,i] #    Dødsfald for kvinder i år i aldre xmin til xmax
  Etest  <- OEdata$E["Male",,i] # Eksponering for kvinder i år i aldre xmin til xmax
  opt <- optim(c(-4,0.1), function(par) loglike(par,Dtest,Etest,xvec))
  Betahat[i] <- opt$par[2] # beta parametre under Poisson antagelsen for kvinder i år i
  Alphahat[i] <- opt$par[1]# alpha  parametre under Poisson antagelsen for kvinder i år i
}

Betahat_m <- Betahat 
Alphahat_m <- Alphahat

Par_m <- cbind(Alphahat_m, Betahat_m)
Par_f <- cbind(Alphahat_f, Betahat_f)
Par_m
```
We have that number of deaths is Poisson distributed:
$$ D(x,t)\mid E(x,t) \sim Poisson \left(E(x,t)\left(-\log \left(\frac{1}{exp(\alpha_t + \beta_t(x-\bar{x}))+1}\right)\right) \right)$$ 

Calculating $\lambda = \log \left(exp(\alpha_t + \beta_t(x-\bar{x}))+1\right)$ we get the value for each year:
```{r}
age <- matrix(seq(xmin,xmax, by = 1),ncol = 1)
lambda <- matrix(log(exp(Par_m[,1]+Par_m[,2]*(age[,1]-xbar))+1), nrow = 49, ncol = 81)
lambda <- log(exp(Par_m[,1]+Par_m[,2]*(age[]-xbar))+1)
```


Mangler plot og sammenligning

## Problem 2.3
As in the original work (Cairns et al. (2006), p. 6), we use a two- dimensional random walk with drift to forecast the model. Estimate the model for each sex and state the parameters. In your opinion, is the use of a random walk structure justifiable?

We want to forecast the model by using a two-dimensional random walk:

$$A(t+1)=A(t)+\mu+CZ(t+1)$$
where $\mu$ is a constant 2x1 matrix, C is an upper triangular matrix and Z(t) is a two-dimensional standard normal random variable. We choose $\mu = (\mu_1, \mu_2)$ to be the difference between the last two observations:
```{r}
mu <- matrix(data = NA, nrow = 2, ncol = 1)
mu <- matrix(c(mortdat$mu[1,,49]- mortdat$mu[1,,48],mortdat$mu[2,,49]- mortdat$mu[2,,48]), nrow = 81, ncol = 2)
mu_model <- matrix(c(mean(mu[,1]),mean(mu[,2])))
tail(fert$histNormalPar$SDAgeMother,1)

mort <- mortClass$new(OEdata)
mortdat <- mort$getMu(timelim = c(1970, 2018))

mortdat$mu[1,,49]- mortdat$mu[1,,48]
mortdat$mu[1,,2]
mortdat$mu
dimnames(mortdat$mu)
```

```{r}
head(mortdat$mu)
```



## Virker ikke! herfra og ned
```{r, eval = FALSE}
# 3- make an estimation
Like <- function(Theta){
  alpha <- Theta[1] 
  beta <- Theta[2]
  kappa <- Theta[3]
  return(aggregate()log(beta)+((1/gamma)+1)*sum(log(1+(gamma/beta)*YY)))
}
optim(c(10,10), logLike)
B <- optim(c(10,10), logLike)$par[1]
G <- optim(c(10,10), logLike)$par[2]

optim(-log)
```

```{r, eval = FALSE}
# length(OEdata$E)
# seq(1970,2018, by = 1)
alpha_0 <- 0
beta_0 <- 1
kappa_0 <- 0
Dhat <- OEdata$E * exp(alpha_0+beta_0*kappa_0)
Dt <- aggregate(FUN= sum, x=OEdata$O, by = list(Year=OEdata$timelim)) #need to get years: 1970-2018
Dx <- aggregate(FUN= sum, x=OEdata$O, by = list(Age = OEdata$agelim )) #not correct. need to get ages from 20 to 100 and not age 20 and age 100
sumDhat_t <- NA
sumDhat_x <- NA
for(i in 1:length(OEdata$E)){
  sumDhat_t <- aggregate(FUN=sum, x = Dhat, by = list(Year = OEdata$timelim)) 
                                #need to get years: 1970-2018
  sumDhat_x <- aggregate(FUN=sum, x = Dhat, by = list(Year = OEdata$agelim))
                      #not correct. need to get ages from 20 to 100 and not age 20 and age 100

  alpha[i] <- alpha_0-((Dt-sumDhat_t)/(-sumDhat_t))
  alpha_0 <- alpha[i]
  Dhat <- OEdata$E * exp(alpha_0+beta_0*kappa_0)
  sumDhat_t <- aggregate(FUN=sum, x = Dhat, by = list(Year = OEdata$timelim)) 
                                #need to get years: 1970-2018
  sumDhat_x <- aggregate(FUN=sum, x = Dhat, by = list(Year = OEdata$agelim))
                      #not correct. need to get ages from 20 to 100 and not age 20 and age 100
  kappa[i] <- kappa_0-((Dx-sumDhat_x)*beta_0)/(-sumDhat_x *(beta_0)^2)
  kappa_0 <- kappa[i]
  Dhat <- OEdata$E * exp(alpha_0+beta_0*kappa_0)
  sumDhat_t <- aggregate(FUN=sum, x = Dhat, by = list(Year = OEdata$timelim)) 
                                #need to get years: 1970-2018
  sumDhat_x <- aggregate(FUN=sum, x = Dhat, by = list(Year = OEdata$agelim))
                      #not correct. need to get ages from 20 to 100 and not age 20 and age 100
  beta[i] <- beta_0-((Dt-sumDhat_t)*kappa_0)/(-sumDhat_t*(kappa_0)^2)
  beta_0 <- beta[i]
  Dhat <- OEdata$E * exp(alpha_0+beta_0*kappa_0)
}


```

```{r, eval = FALSE}
age <- 100-20
years <- 2018-1970
man 2
dim age years
lab X T
mod {wei(XT), X, spe(T,1a,X,b)} 
dat OEdata$O
sta wei(XT) OEdata$E
```
The likelihood function is
$$L(\alpha,\beta, \kappa) =\sum_{x,t}\lbrace D_{xt}(\alpha_x+\beta_x\kappa_t)-E_{xt}exp(\alpha_x+\beta_x\kappa_t)\rbrace + constant$$
$$ =  $$

Dropping the constant and calculating the log-likelihood we get:

$$l(\alpha,\beta,\kappa) = 
alpha = 1x80
beta = 1x80
kappa = 1x48$$
```{r, eval = FALSE}
# 3- make an estimation
Like <- function(Theta){
  alpha <- Theta[1] 
  beta <- Theta[2]
  kappa <- Theta[3]
  return(aggregate()log(beta)+((1/gamma)+1)*sum(log(1+(gamma/beta)*YY)))
}
optim(c(10,10), logLike)
B <- optim(c(10,10), logLike)$par[1]
G <- optim(c(10,10), logLike)$par[2]

optim(-log)
```


